# Lab 9 - ea strategies for 1000-loci genome

## <u>Strategies</u>
The objective was to minimize the number of fitness calls, while solving the proposed problem with different instances.
The following strategies have been tried, with the goal to improve the efficency of the Evolutionary Algorithm:

**<u>The updated code doesn't include all the strategies discussed below, but their relative implementation can be retrieved from previous commits</u>**
1. <u>Simulated Anealing</u>: allowing worse individuals with a certain probability `p=exp(-(f1-f2)/T)`, with the goal of exiting from a local minimum and search solutions that follow another path wrt to the current best individuals. The strategy was discard due to the lack of results (see previous commits). Simulated Anelaing was activated any time the fitness wasn't improving for a long time.
2. <u>Elitism</u>: reserve a portion of population only for offsprings, in this way exploration is privileged. This strategy was also discarded since doesn't bring any improvements to the algorithm. This strategy was activated only when the fitness seemed to be stuck at a certain stagnant point.
3. <u>Tabu Search</u> building a table that acts as a cache, it would store all the genotypes visited in the recent past. This prevents the algorithm to look for states that have already been analized. Due to the fact that the genotpe was 1000 bits long the probaility of generating 2 same individuals is neglectable, thus excluding tabu search as a possible solution to decrease computation (the hits to the table were very few and uneffective even if the table occupied 4kB).
4. <u>Ilsands</u>: divide the population into n islands, that would act as n different populations evolving by themselves. Migration of individuals from one island to another are performed with a certain rate. The subdivision of the individuals into the islands is performed randomly. Even thought the island model could help to reduce the number of generations, it produces more fitness calls, since the different offsprings are generated for each island. Since the objective is to utilize the less fitness calls we can, we leave the updated code with the number of islands equal to 1 (but the code is already there to try different values).
```py
if gen != 0 and gen % MIGRATION_RATE == 0:
            migrants = list()
            for isl in range(ISLANDS):
                migrants.append(islands[isl][:MIGRANTS])

            # circular migration
            for isl in range(ISLANDS):
                if isl == ISLANDS- 1:
                    islands[0][:MIGRANTS] = migrants[isl]
                else:
                    islands[isl + 1][:MIGRANTS] = migrants[isl]
```
5. <u>n_cut_xover</u>: when performing crossover, the two parents are subdivided into n different slices, and the offspring is generated by recombining alternatively the slices from the parents. This helps a lot, instead of doing a 1 point crossover. Specifically the n_cut_xover is performed by cutting the parents into a random number from 1 to 10. Apparently there's a better xover i will explain in the next strategy
```py
def n_cut_xover(ind1: Individual, ind2: Individual, cuts: int) -> Individual:
    cut_points = np.linspace(0, LOCI_GENOMES, cuts + 1, dtype=int)
    inds = (ind1, ind2)
    ind_turn = 0
    prev_cut_point = 0
    offspring = Individual(genotype=np.zeros(LOCI_GENOMES), fitness=None)

    for cut in cut_points:
        offspring.genotype[prev_cut_point:cut] = inds[ind_turn].genotype[prev_cut_point:cut]
        prev_cut_point = cut
        ind_turn = 1 - ind_turn

    assert len(offspring.genotype) == LOCI_GENOMES

    return offspring
```
6. <u>Random Crossover</u>: I took inspiration from Stiven Hidri (https://github.com/stiven-hidri/CI2324/) which implements a crossover on multiple random genomes.
```py
def random_xover(ind1: Individual, ind2: Individual) -> Individual:
    n_genomes = int(rnd.choice(np.linspace(1, LOCI_GENOMES, LOCI_GENOMES)))
    genomes = rnd.sample(range(LOCI_GENOMES), k=n_genomes)
    offspring = deepcopy(ind1)
    for g in genomes:
        offspring.genotype[g] = ind2.genotype[g] 
    return offspring
``` 
7. <u>Steady State Termination</u>: the algorithm stops if the fitness remained the same for a long time. This prevents the waste of useless fitness calls that wouldn't improve by any mean the individuals.
```py
if gen != 0 and gen % STEADY_STATE_RATE == 0:
                delta_fitness = y[isl][gen] - y[isl][gen - STEADY_STATE_RATE]
                if delta_fitness < THRESHOLD_IMPROVEMENT:
                    steady_state[isl] = True
                else:
                    steady_state[isl] = False
```
8. <u>Shuffling of genes</u>: While searching which type of mutation could benefit the improvements of our fitness i took inspiration from Stiven Hidri (https://github.com/stiven-hidri/CI2324/), which said that shuffling genes was providing him good results. Indeed shuffling genes is a good strategy to obtain better indiviudals in less generations.

## <u>Genetic Algorithm</u>
The genetic algorithms follows the standard rules of GA. The only worthly part is how mutation/xover are performed:

1. starting from parent p1, we shuffle it
2. we then perform a mutation over this new individual
3. we then proceed to make a crossover between this modified individual and a second one p2

Parent selection is performed with TOURNAMENT_SIZE = 25, which reflects pretty heavy selectiv pressure.

## <u>Hyperparameters</u>
We discuss here the motivation behind the coiche of the numeric values of the most important hyperparameters:
1. <u>POPULATION_SIZE</u>: i observed that it is not necessary to have a big amount of individuals in the population, it will take more time but the reduction of fitness calls is drastic.
2. <u>OFFSPRINGS</u>: the number offsprings is correlated to the POPULATION_SIZE, but it follows the same reasons i discussed before
3. <u>THRESHOLD_IMPROVEMENT</u>: it is set to `1e-3` since it's a good precision for our fitness. Most of the times the most computation is performed just to go from 0.999 to 1.
4. <u>STEADY_STATE_RATE</u>: `200` generations of steady fitness are enough to establish that hoping on better individuals in the next recent generations is not worth it.

## <u>Results</u>
The results are shown in the `lab9_results.png` image. It shows 4 graphs relative to different problem instances. Each graph tells how many fitness calls were used and how the fitness value changed during the generations. At the bottom there are the most important hyperparameters. 